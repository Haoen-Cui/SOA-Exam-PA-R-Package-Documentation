<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Relaxed fits and other additions in `glmnet` 3.0 • glmnet</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Relaxed fits and other additions in `glmnet` 3.0">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">glmnet</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">3.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa fas fa-archive fa-lg"></span>
     
    R Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../boot/index.html">boot</a>
    </li>
    <li>
      <a href="../../broom/index.html">broom</a>
    </li>
    <li>
      <a href="../../caret/index.html">caret</a>
    </li>
    <li>
      <a href="../../cluster/index.html">cluster</a>
    </li>
    <li>
      <a href="../../coefplot/index.html">coefplot</a>
    </li>
    <li>
      <a href="../../data.table/index.html">data.table</a>
    </li>
    <li>
      <a href="../../devtools/index.html">devtools</a>
    </li>
    <li>
      <a href="../../dplyr/index.html">dplyr</a>
    </li>
    <li>
      <a href="../../e1071/index.html">e1071</a>
    </li>
    <li>
      <a href="../../forcats/index.html">forcats</a>
    </li>
    <li>
      <a href="../../gbm/index.html">gbm</a>
    </li>
    <li>
      <a href="../../ggplot2/index.html">ggplot2</a>
    </li>
    <li>
      <a href="../../glmnet/index.html">glmnet</a>
    </li>
    <li>
      <a href="../../gridExtra/index.html">gridExtra</a>
    </li>
    <li>
      <a href="../../ISLR/index.html">ISLR</a>
    </li>
    <li>
      <a href="../../MASS/index.html">MASS</a>
    </li>
    <li>
      <a href="../../pdp/index.html">pdp</a>
    </li>
    <li>
      <a href="../../pls/index.html">pls</a>
    </li>
    <li>
      <a href="../../plyr/index.html">plyr</a>
    </li>
    <li>
      <a href="../../pROC/index.html">pROC</a>
    </li>
    <li>
      <a href="../../purrr/index.html">purrr</a>
    </li>
    <li>
      <a href="../../randomForest/index.html">randomForest</a>
    </li>
    <li>
      <a href="../../readr/index.html">readr</a>
    </li>
    <li>
      <a href="../../rpart/index.html">rpart</a>
    </li>
    <li>
      <a href="../../rpart.plot/index.html">rpart.plot</a>
    </li>
    <li>
      <a href="../../stringr/index.html">stringr</a>
    </li>
    <li>
      <a href="../../tibble/index.html">tibble</a>
    </li>
    <li>
      <a href="../../tidyr/index.html">tidyr</a>
    </li>
    <li>
      <a href="../../xgboost/index.html">xgboost</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/glmnet.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Coxnet.html">Coxnet: Regularized Cox Regression</a>
    </li>
    <li>
      <a href="../articles/relax.html">Relaxed fits and other additions in `glmnet` 3.0</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Relaxed fits and other additions in <code>glmnet</code> 3.0</h1>
                        <h4 class="author">Trevor Hastie, Balasubramanian Narasimhan and Rob Tibshirani</h4>
            
            <h4 class="date">October 15, 2019</h4>
      
      
      <div class="hidden name"><code>relax.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>In our vignette “glmnet” we give details for fitting lasso and elastic-net regularized models, for CV and various aspects of glmnet modeling. In this vignette, we highlight some of the new tools and features in the major revision glmnet 3.0.</p>
<p>The main edition is the introduction of the <em>relaxed lasso</em>. The idea is to take a glmnet fitted object, and then for each lambda, refit the variables in the active set without any penalization. This gives the <code>relaxed</code> fit (note, there have been other definitions of a relaxed fit, but this is the one we prefer). This could of course be done for elastic net fits as well as lasso. However, if the number of variables gets too close to the sample size N, the relaxed path will be truncated. Furthermore, for binomial and other nonlinear GLMs convergence can be an issue with our current implementation if the number of variables is too large, and perversely if the relaxed fit is too strong.</p>
<p>Suppose the <code>glmnet</code> fitted linear predictor at <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(\hat\eta_\lambda(x)\)</span> and the relaxed version is <span class="math inline">\(\tilde \eta_\lambda(x)\)</span>. We also allow for shrinkage between the two: <span class="math display">\[\tilde \eta_{\lambda,\gamma}=(1-\gamma)\tilde
\eta_\lambda(x)+\gamma\hat\eta_\lambda(x).\]</span> <span class="math inline">\(\gamma\in[0,1]\)</span> is an additional tuning parameter which can be selected by cross validation.</p>
<p>The debiasing will potentially improve prediction performance, and CV will typically select a model with a smaller number of variables. This procedure is very competitive with forward-stepwise and best-subset regression, and has a considerable speed advantage when the number of variables is large. This is especially true for best-subset, but even so for forward stepwise. The latter has to plod through the variables one-at-a-time, while glmnet will just plunge in and find a good active set.</p>
<p>Further details may be found in <span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-glmnet">2010</a>)</span>, <span class="citation">Simon et al. (<a href="#ref-coxnet">2011</a>)</span>, <span class="citation">Tibshirani et al. (<a href="#ref-strongrules">2012</a>)</span>, <span class="citation">Simon, Friedman, and Hastie (<a href="#ref-block">2013</a>)</span> and <span class="citation">Hastie, Tibshirani, and Tibshirani (<a href="#ref-best_subset">2017</a>)</span>.</p>
</div>
<div id="simple-relaxed-fit" class="section level2">
<h2 class="hasAnchor">
<a href="#simple-relaxed-fit" class="anchor"></a>Simple relaxed fit</h2>
<p>To get things going, we show the most basic use. We use the same data used in the <code>glmnet</code> vignette.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(glmnet)</a></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loaded glmnet 3.0-1</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(QuickStartExample)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">fit=<span class="kw"><a href="../reference/glmnet.html">glmnet</a></span>(x,y, <span class="dt">relax=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(fit)</a></code></pre></div>
<pre><code>## 
## Call:  glmnet(x = x, y = y, relax = TRUE) 
## Relaxed
## 
##    Df    %Dev %Dev R  Lambda
## 1   0 0.00000 0.0000 1.63100
## 2   2 0.05528 0.5890 1.48600
## 3   2 0.14590 0.5890 1.35400
## 4   2 0.22110 0.5890 1.23400
## 5   2 0.28360 0.5890 1.12400
## 6   2 0.33540 0.5890 1.02400
## 7   4 0.39040 0.7656 0.93320
## 8   5 0.45600 0.8059 0.85030
## 9   5 0.51540 0.8059 0.77470
## 10  6 0.57350 0.8799 0.70590
## 11  6 0.62550 0.8799 0.64320
## 12  6 0.66870 0.8799 0.58610
## 13  6 0.70460 0.8799 0.53400
## 14  6 0.73440 0.8799 0.48660
## 15  7 0.76210 0.9010 0.44330
## 16  7 0.78570 0.9010 0.40400
## 17  7 0.80530 0.9010 0.36810
## 18  7 0.82150 0.9010 0.33540
## 19  7 0.83500 0.9010 0.30560
## 20  7 0.84620 0.9010 0.27840
## 21  7 0.85550 0.9010 0.25370
## 22  7 0.86330 0.9010 0.23120
## 23  8 0.87060 0.9077 0.21060
## 24  8 0.87690 0.9077 0.19190
## 25  8 0.88210 0.9077 0.17490
## 26  8 0.88650 0.9077 0.15930
## 27  8 0.89010 0.9077 0.14520
## 28  8 0.89310 0.9077 0.13230
## 29  8 0.89560 0.9077 0.12050
## 30  8 0.89760 0.9077 0.10980
## 31  9 0.89940 0.9087 0.10010
## 32  9 0.90100 0.9087 0.09117
## 33  9 0.90230 0.9087 0.08307
## 34  9 0.90340 0.9087 0.07569
## 35 10 0.90430 0.9096 0.06897
## 36 11 0.90530 0.9109 0.06284
## 37 11 0.90620 0.9109 0.05726
## 38 12 0.90700 0.9113 0.05217
## 39 15 0.90780 0.9123 0.04754
## 40 16 0.90860 0.9126 0.04331
## 41 16 0.90930 0.9126 0.03947
## 42 16 0.90980 0.9126 0.03596
## 43 17 0.91030 0.9128 0.03277
## 44 17 0.91070 0.9128 0.02985
## 45 18 0.91110 0.9131 0.02720
## 46 18 0.91140 0.9131 0.02479
## 47 19 0.91170 0.9132 0.02258
## 48 19 0.91200 0.9132 0.02058
## 49 19 0.91220 0.9132 0.01875
## 50 19 0.91240 0.9132 0.01708
## 51 19 0.91250 0.9132 0.01557
## 52 19 0.91260 0.9132 0.01418
## 53 19 0.91270 0.9132 0.01292
## 54 19 0.91280 0.9132 0.01178
## 55 19 0.91290 0.9132 0.01073
## 56 19 0.91290 0.9132 0.00978
## 57 19 0.91300 0.9132 0.00891
## 58 19 0.91300 0.9132 0.00812
## 59 19 0.91310 0.9132 0.00740
## 60 19 0.91310 0.9132 0.00674
## 61 19 0.91310 0.9132 0.00614
## 62 20 0.91310 0.9132 0.00559
## 63 20 0.91310 0.9132 0.00510
## 64 20 0.91310 0.9132 0.00464
## 65 20 0.91320 0.9132 0.00423
## 66 20 0.91320 0.9132 0.00386
## 67 20 0.91320 0.9132 0.00351</code></pre>
<p>There is an extra column <code>%Dev R</code> where the <code>R</code> stands for “relaxed”, which is the percent deviance explained by the relaxed fit. This is always higher than its neighboring column, which is the same for the penalized fit (on the training data).</p>
<p>The fit object is class <code>relaxed</code>, which inherits from class <code>glmnet</code>. One can plot it, with additional flexibility.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/graphics/par.html">par</a></span>(<span class="dt">mfrow=</span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(fit)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(fit,<span class="dt">gamma=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(fit,<span class="dt">gamma=</span><span class="dv">0</span>)</a></code></pre></div>
<p><img src="relax_files/figure-html/unnamed-chunk-2-1.png" width="700"></p>
<p>So again, <code>gamma=1</code> is the traditional <code>glmnet</code> fit, while <code>gamma=0</code> is the unpenalized fit, and <code>gamma=0.5</code> is a mixture of the two (at the coefficient level, and hence also the linear predictors).</p>
<p>We can also select <code>gamma</code> using <code>cv.glmnet</code>, which by default uses the 5 values <code><a href="https://rdrr.io/r/base/c.html">c(0, 0.25, 0.5, 0.75, 1)</a></code>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">relax=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(cfit)</a></code></pre></div>
<p><img src="relax_files/figure-html/unnamed-chunk-3-1.png" width="700"></p>
<p>The plot command has an <code>se.bands</code> option if you don’t like the default shading of these bands.</p>
<p>Just like before, you can make predictions from a CV object, and it uses the selected values for <code>lambda</code> and <code>gamma</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(cvfit,newx)</a></code></pre></div>
<p>A new feature in <code>glmnet</code> is a print method for <code>cv.glmnet</code> and a <code>cv.relaxed</code> object.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(cfit)</a></code></pre></div>
<pre><code>## 
## Call:  cv.glmnet(x = x, y = y, relax = TRUE) 
## 
## Measure: Mean-Squared Error 
## 
##     Gamma Lambda Measure     SE Nonzero
## min     0 0.3056  0.9831 0.1294       7
## 1se     0 0.4433  1.0787 0.1482       7</code></pre>
</div>
<div id="more-details-on-relaxed-fitting" class="section level2">
<h2 class="hasAnchor">
<a href="#more-details-on-relaxed-fitting" class="anchor"></a>More details on relaxed fitting</h2>
<p>Although <code>glmnet</code> has a <code>relax</code> option, you can created a relaxed version by post-processing a <code>glmnet</code> object.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">fit=<span class="kw"><a href="../reference/glmnet.html">glmnet</a></span>(x,y)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">fitr=<span class="kw"><a href="../reference/glmnet.html">relax.glmnet</a></span>(fit,<span class="dt">x=</span>x,<span class="dt">y=</span>y)</a></code></pre></div>
<p>This will rarely need to be done; one use case is if the original fit took a long time, and the user wanted to avoid refitting it. Note that in the call the arguments are named, since they are passed in via the <code>...</code> argument to <code>relax.glmnet</code>.</p>
<p>Needless to say, <em>any</em> of the families fit by <code>glmnet</code> can also be fit with the <code>relaxed</code> option.</p>
<p>As mentioned, a <code>relaxed</code> object is also a <code>glmnet</code> object. Apart from the class modification, it has an additional componet named <code>relaxed</code> which is itself a <code>glmnet</code> object, but with the relaxed coefficients. The default behavior of extractor functions like <code>predict</code> and <code>coef</code>, as well as <code>plot</code> will be to present results from the <code>glmnet</code> fit, unless a value of <code>gamma</code> is given different from the default value <code>gamma=1</code> (see the plots above). The <code>print</code> method gives additional info on the relaxed fit.</p>
<p>Likewise, a <code>cv.relaxed</code> object inherits from class <code>cv.glmnet</code>. Here the <code>predict</code> method by default uses the optimal relaxed fit; if predictions from the CV-optimal <em>original</em> <code>glmnet</code> fit are desired, one can directly use <code>predict.cv.glmnet</code>. Similarly for the <code>print</code> command, which we illustrate here.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(cfit)</a></code></pre></div>
<pre><code>## 
## Call:  cv.glmnet(x = x, y = y, relax = TRUE) 
## 
## Measure: Mean-Squared Error 
## 
##     Gamma Lambda Measure     SE Nonzero
## min     0 0.3056  0.9831 0.1294       7
## 1se     0 0.4433  1.0787 0.1482       7</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw"><a href="../reference/print.cv.glmnet.html">print.cv.glmnet</a></span>(cfit)</a></code></pre></div>
<pre><code>## 
## Call:  cv.glmnet(x = x, y = y, relax = TRUE) 
## 
## Measure: Mean-Squared Error 
## 
##      Lambda Measure     SE Nonzero
## min 0.08307   1.054 0.1513       9
## 1se 0.15933   1.192 0.2042       8</code></pre>
</div>
<div id="relaxed-fits-and-glms" class="section level2">
<h2 class="hasAnchor">
<a href="#relaxed-fits-and-glms" class="anchor"></a>Relaxed fits and glms</h2>
<p><code>glmnet</code> itself is used to fit the relaxed fits, by using a single value of zero for <code>lambda</code>. However, for nonlinear models such as binomial, multinomial and poisson, there can be convergence issues. This is because <code>glmnet</code> does not do stepsize optimization, rather relying on the pathwise fit to stay in the “quadratic” zone of the log likelihood. We have an optional <code>path=TRUE</code> option for <code>relax.glmnet</code>, which actually fits a regurized path toward the <code>lambda=0</code> solution, and thus avoids the issue. The default is <code>path=FALSE</code> since this option adds to the computing time.</p>
<div id="forward-stepwise-and-relaxed-fit" class="section level3">
<h3 class="hasAnchor">
<a href="#forward-stepwise-and-relaxed-fit" class="anchor"></a>Forward stepwise and relaxed fit</h3>
<p>One use case for a relaxed fit is as a faster version of forward stepwise regression. With a large number <code>p</code> of variables, forward-stepwise regression can be tedious. Lasso on the other hand, because of its convexity, can plunge in and identify good candidate sets of variables over 100 values of <code>lambda</code>, even though <code>p</code> could be in the 10s of thousands. In a case like this, one can have <code>cv.glmnet</code> do the selection.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">fitr=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">gamma=</span><span class="dv">0</span>,<span class="dt">relax=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(fitr)</a></code></pre></div>
<p><img src="relax_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>Notice that we only allow <code>gamma=0</code>, so in this case we are not considering the blended fits.</p>
<p><a id="progress"></a></p>
</div>
</div>
<div id="progress-bar" class="section level2">
<h2 class="hasAnchor">
<a href="#progress-bar" class="anchor"></a>Progress bar</h2>
<p>We finally have a progress bar for <code>glmnet</code> and <code>cv.glmnet</code>. Ever run a job on a big dataset, and wonder how long it will take? Now you can use the <code>trace.it = TRUE</code> argument to these functions.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">fit=<span class="kw"><a href="../reference/glmnet.html">glmnet</a></span>(x,y,<span class="dt">trace=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><code>##</code></p>
<p><code>|==================================           |65%</code></p>
<p>Here we abbreviated the argument to <code>trace</code>. This display changes in place as the fit is produced. Also very helpful with <code>cv.glmnet</code></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">fit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">trace=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><code>##</code></p>
<p><code>Training</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 1/10</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 2/10</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 3/10</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 4/10</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 5/10</code></p>
<p><code>|=============================================| 100%</code></p>
<p><code>Fold: 6/10</code></p>
<p><code>|=============================                |  70%</code></p>
<p>Tracing of the folds works a little differently when distributed computing is used.</p>
<p>Here the <code>trace</code> argument should be used in each call to <code>glmnet</code> or <code>cv.glmnet</code>. One can set this option session wide via a call to <code>glmnet.control</code> with its new <code>itrace</code> argument:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="kw"><a href="../reference/glmnet.control.html">glmnet.control</a></span>(<span class="dt">itrace=</span><span class="dv">1</span>)</a></code></pre></div>
<p>To reset it, one makes a similar call and sets <code>itrace=0</code>.</p>
</div>
<div id="c-index-for-cox-models" class="section level2">
<h2 class="hasAnchor">
<a href="#c-index-for-cox-models" class="anchor"></a>C index for Cox models</h2>
<p>We have a new performance measure for the Cox model: the Harrel <em>C index</em>. This is like the AUC measure of concordance for survival data, but only considers comparable pairs. Pure concordance would record the fraction of pairs for which the order of the death times agree with the order of the predicted risk. But with survival data, if an observation is right censored at a time <em>before</em> another observation’s death time, they are not comparable.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"> <span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(CoxExample)</a></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"> cvfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">family=</span><span class="st">"cox"</span>,<span class="dt">type.measure=</span><span class="st">"C"</span>)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"> <span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(cvfit)</a></code></pre></div>
<p><img src="relax_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
</div>
<div id="assessing-models-on-test-data" class="section level2">
<h2 class="hasAnchor">
<a href="#assessing-models-on-test-data" class="anchor"></a>Assessing models on test data</h2>
<p>Once we have fit a series of models using <code>glmnet</code>, we often assess their performance on a set of evaluation or test data. We usually go through the process of building a prediction matrix, and then deciding on the measure, and computing the values for a series of values for <code>lambda</code> and now <code>gamma</code>. Here we provide three functions for making these tasks easier.</p>
<div id="performance-measures" class="section level3">
<h3 class="hasAnchor">
<a href="#performance-measures" class="anchor"></a>Performance measures</h3>
<p>The function <code>assess.glmnet</code> computes the same performance measures produced by <code>cv.glmnet</code>, but on a validation or test dataset.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(BinomialExample)</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">itrain=<span class="dv">1</span><span class="op">:</span><span class="dv">70</span></a>
<a class="sourceLine" id="cb22-3" data-line-number="3">fit=<span class="kw"><a href="../reference/glmnet.html">glmnet</a></span>(x[itrain,],y[itrain],<span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">nlambda=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb22-4" data-line-number="4"><span class="kw"><a href="../reference/assess.glmnet.html">assess.glmnet</a></span>(fit,<span class="dt">newx=</span>x[<span class="op">-</span>itrain,],<span class="dt">newy=</span>y[<span class="op">-</span>itrain])</a></code></pre></div>
<pre><code>## $deviance
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 1.3877348 1.2319096 1.0555731 0.9020831 0.8564873 0.8716707 0.9415079 1.0669161 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 1.3180742 1.6236987 1.9513754 2.2105092 2.4922882 2.7629164 2.9792768 3.1275960 
##       s16       s17       s18 
## 3.2759824 3.4240188 3.5722750 
## attr(,"measure")
## [1] "Binomial Deviance"
## 
## $class
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 0.4666667 0.3333333 0.2000000 0.1666667 0.1666667 0.1666667 0.2000000 0.2000000 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.2000000 0.2333333 0.2333333 0.2000000 0.2000000 0.2000000 0.1666667 0.1666667 
##       s16       s17       s18 
## 0.1666667 0.1666667 0.1666667 
## attr(,"measure")
## [1] "Misclassification Error"
## 
## $auc
##  [1] 0.7276786 0.7991071 0.8437500 0.8928571 0.9017857 0.9062500 0.8973214
##  [8] 0.8928571 0.8705357 0.8526786 0.8392857 0.8214286 0.8214286 0.8169643
## [15] 0.8169643 0.8169643 0.8125000 0.8125000 0.8080357
## attr(,"measure")
## [1] "AUC"
## 
## $mse
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 0.5006803 0.4265596 0.3477022 0.2836649 0.2605716 0.2537474 0.2701316 0.2937508 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.3324507 0.3610377 0.3651420 0.3570217 0.3549473 0.3535171 0.3514806 0.3496168 
##       s16       s17       s18 
## 0.3480045 0.3467192 0.3455224 
## attr(,"measure")
## [1] "Mean-Squared Error"
## 
## $mae
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 0.9904762 0.8979473 0.7675067 0.6352868 0.5533314 0.5012508 0.4736140 0.4565569 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.4683982 0.4715432 0.4538161 0.4305615 0.4135260 0.4026998 0.3941315 0.3871481 
##       s16       s17       s18 
## 0.3816993 0.3776846 0.3744014 
## attr(,"measure")
## [1] "Mean Absolute Error"</code></pre>
<p>This produces a list with <em>all</em> the measures suitable for a binomial model, computed for the entire sequence of lambdas in the fit object. Here the function identifies the model family from the fit object.</p>
<p>A second use case builds the prediction matrix first</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">pred=<span class="kw"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(fit,<span class="dt">newx=</span>x[<span class="op">-</span>itrain,])</a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="kw"><a href="../reference/assess.glmnet.html">assess.glmnet</a></span>(pred,<span class="dt">newy=</span>y[<span class="op">-</span>itrain],<span class="dt">family=</span><span class="st">"binomial"</span>)</a></code></pre></div>
<p>Here we have to provide the <code>family</code> as an argument; the results (not shown) are the same. Users can see the various measures suitable for each family via</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw"><a href="../reference/glmnet.measures.html">glmnet.measures</a></span>()</a></code></pre></div>
<pre><code>## $gaussian
## [1] "mse" "mae"
## 
## $binomial
## [1] "deviance" "class"    "auc"      "mse"      "mae"     
## 
## $poisson
## [1] "deviance" "mse"      "mae"     
## 
## $cox
## [1] "deviance" "C"       
## 
## $multinomial
## [1] "deviance" "class"    "mse"      "mae"     
## 
## $mgaussian
## [1] "mse" "mae"</code></pre>
<p>The assess function can also take the result of <code>cv.glmnet</code> as input. In this case the predictions are made at the optimal values for the parameter(s).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x[itrain,],y[itrain],<span class="dt">family=</span><span class="st">"binomial"</span>, <span class="dt">nlambda =</span> <span class="dv">30</span>)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw"><a href="../reference/assess.glmnet.html">assess.glmnet</a></span>(cfit,<span class="dt">newx=</span>x[<span class="op">-</span>itrain,],<span class="dt">newy=</span>y[<span class="op">-</span>itrain])</a></code></pre></div>
<pre><code>## $deviance
##         1 
## 0.9482246 
## attr(,"measure")
## [1] "Binomial Deviance"
## 
## $class
##   1 
## 0.2 
## attr(,"measure")
## [1] "Misclassification Error"
## 
## $auc
## [1] 0.875
## attr(,"measure")
## [1] "AUC"
## 
## $mse
##         1 
## 0.3028376 
## attr(,"measure")
## [1] "Mean-Squared Error"
## 
## $mae
##         1 
## 0.6797343 
## attr(,"measure")
## [1] "Mean Absolute Error"</code></pre>
<p>This used the default value of <code>s=lambda.1se</code>, just like <code>predict</code> would have done. Users can provide additional arguments that get passed on to predict:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw"><a href="../reference/assess.glmnet.html">assess.glmnet</a></span>(cfit,<span class="dt">newx=</span>x[<span class="op">-</span>itrain,],<span class="dt">newy=</span>y[<span class="op">-</span>itrain], <span class="dt">s=</span><span class="st">"lambda.min"</span>)</a></code></pre></div>
<pre><code>## $deviance
##        1 
## 0.877155 
## attr(,"measure")
## [1] "Binomial Deviance"
## 
## $class
##         1 
## 0.1666667 
## attr(,"measure")
## [1] "Misclassification Error"
## 
## $auc
## [1] 0.8973214
## attr(,"measure")
## [1] "AUC"
## 
## $mse
##        1 
## 0.273071 
## attr(,"measure")
## [1] "Mean-Squared Error"
## 
## $mae
##         1 
## 0.6069619 
## attr(,"measure")
## [1] "Mean Absolute Error"</code></pre>
<p>One interesting use case is to get the results of CV using other measures, via the <code>keep</code> argument. In this case the <code>fit.preval</code> object is a matrix of prevalidated predictions made using the folds <code>foldid</code></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">keep=</span><span class="ot">TRUE</span>, <span class="dt">nlambda =</span> <span class="dv">30</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw"><a href="../reference/assess.glmnet.html">assess.glmnet</a></span>(cfit<span class="op">$</span>fit.preval,<span class="dt">newy=</span>y,<span class="dt">family=</span><span class="st">"binomial"</span>)</a></code></pre></div>
<pre><code>## $deviance
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 1.3876960 1.2767978 1.1836116 1.1011943 1.0017412 0.9008072 0.8297499 0.7942998 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.7924199 0.8187557 0.8735849 0.9551737 1.0670542 1.2134478 1.3939337 1.5919928 
##       s16       s17       s18       s19       s20       s21       s22       s23 
## 1.7913609 1.9602808 2.0982748 2.2212444 2.3371396 2.4542577 2.5547655 2.6520462 
##       s24       s25       s26       s27       s28       s29 
## 2.7377531 2.8153457 2.8760356 2.9101258 2.9319111 2.9431985 
## attr(,"measure")
## [1] "Binomial Deviance"
## 
## $class
##   s0   s1   s2   s3   s4   s5   s6   s7   s8   s9  s10  s11  s12  s13  s14  s15 
## 0.44 0.31 0.26 0.27 0.20 0.18 0.18 0.14 0.14 0.15 0.15 0.16 0.18 0.20 0.20 0.19 
##  s16  s17  s18  s19  s20  s21  s22  s23  s24  s25  s26  s27  s28  s29 
## 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.20 0.20 0.20 0.20 0.20 
## attr(,"measure")
## [1] "Misclassification Error"
## 
## $auc
##  [1] 0.3814935 0.7658279 0.7844968 0.8157468 0.8474026 0.8806818 0.8969156
##  [8] 0.9025974 0.9042208 0.9042208 0.8981331 0.8952922 0.8900162 0.8879870
## [15] 0.8859578 0.8871753 0.8875812 0.8883929 0.8871753 0.8871753 0.8863636
## [22] 0.8867695 0.8867695 0.8859578 0.8863636 0.8863636 0.8859578 0.8863636
## [29] 0.8859578 0.8863636
## attr(,"measure")
## [1] "AUC"
## 
## $mse
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 0.5006089 0.4459749 0.4018087 0.3649280 0.3239928 0.2837591 0.2559092 0.2395268 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.2333956 0.2323191 0.2356759 0.2449102 0.2610604 0.2823075 0.3003517 0.3106865 
##       s16       s17       s18       s19       s20       s21       s22       s23 
## 0.3169382 0.3219988 0.3266383 0.3312287 0.3356633 0.3397754 0.3435746 0.3470613 
##       s24       s25       s26       s27       s28       s29 
## 0.3502324 0.3530813 0.3557247 0.3581078 0.3599617 0.3594919 
## attr(,"measure")
## [1] "Mean-Squared Error"
## 
## $mae
##        s0        s1        s2        s3        s4        s5        s6        s7 
## 0.9926408 0.9282982 0.8600168 0.7899903 0.7076536 0.6231577 0.5553294 0.5053834 
##        s8        s9       s10       s11       s12       s13       s14       s15 
## 0.4698556 0.4398822 0.4162609 0.4021812 0.3969930 0.3958959 0.3951095 0.3919078 
##       s16       s17       s18       s19       s20       s21       s22       s23 
## 0.3878858 0.3851300 0.3838986 0.3837975 0.3842131 0.3845868 0.3849673 0.3853818 
##       s24       s25       s26       s27       s28       s29 
## 0.3857889 0.3861738 0.3867311 0.3873381 0.3877004 0.3867967 
## attr(,"measure")
## [1] "Mean Absolute Error"</code></pre>
<p>Users can verify that the first measure here <code>deviance</code> is identical to the component <code>cvm</code> on the <code>cfit</code> object.</p>
</div>
<div id="roc-curves-for-binomial-data" class="section level3">
<h3 class="hasAnchor">
<a href="#roc-curves-for-binomial-data" class="anchor"></a>ROC curves for binomial data</h3>
<p>In the special case of binomial models, users often would like to see the ROC curve for validation or test data. Here the function <code>roc.glmnet</code> provides the goodies. Its first argument is as in <code>assess.glmnet</code>. Here we illustrate one use case, using the prevlidated CV fit as before.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">family=</span><span class="st">"binomial"</span>, <span class="dt">type.measure=</span><span class="st">"auc"</span>, <span class="dt">keep=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb33-2" data-line-number="2">rocs=<span class="kw"><a href="../reference/assess.glmnet.html">roc.glmnet</a></span>(cfit<span class="op">$</span>fit.preval,<span class="dt">newy=</span>y)</a>
<a class="sourceLine" id="cb33-3" data-line-number="3">which=<span class="kw"><a href="https://rdrr.io/r/base/match.html">match</a></span>(cfit<span class="op">$</span>lambda.min,cfit<span class="op">$</span>lambda)</a>
<a class="sourceLine" id="cb33-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(rocs[[which]],<span class="dt">type=</span><span class="st">"l"</span>)</a>
<a class="sourceLine" id="cb33-5" data-line-number="5">nopr=<span class="kw"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span>(rocs,lines,<span class="dt">col=</span><span class="st">"grey"</span>)</a>
<a class="sourceLine" id="cb33-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span>(rocs[[which]],<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="st">"red"</span>)</a></code></pre></div>
<p><img src="relax_files/figure-html/unnamed-chunk-19-1.png" width="700"></p>
<p>In this case <code>roc.glmnet</code> returns a list of cross-validated ROC data, one for each model along the path. In the third line we identify the CV winner. Then we plot all the curves in grey, and the winner in red.</p>
</div>
<div id="confusion-matrices-for-classification" class="section level3">
<h3 class="hasAnchor">
<a href="#confusion-matrices-for-classification" class="anchor"></a>Confusion matrices for classification</h3>
<p>For binomial and multinomial models, we often which to examine the classification performance on new data. The function <code>confusion.glmnet</code> will do that.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(MultinomialExample)</a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">101</span>)</a>
<a class="sourceLine" id="cb34-3" data-line-number="3">itrain=<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(<span class="dv">1</span><span class="op">:</span><span class="dv">500</span>,<span class="dv">400</span>,<span class="dt">replace=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb34-4" data-line-number="4">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x[itrain,],y[itrain],<span class="dt">family=</span><span class="st">"multinomial"</span>)</a>
<a class="sourceLine" id="cb34-5" data-line-number="5">cnf=<span class="kw"><a href="../reference/assess.glmnet.html">confusion.glmnet</a></span>(cfit,<span class="dt">newx=</span>x[<span class="op">-</span>itrain,],<span class="dt">newy=</span>y[<span class="op">-</span>itrain])</a>
<a class="sourceLine" id="cb34-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(cnf)</a></code></pre></div>
<pre><code>##          True
## Predicted  1  2  3 Total
##     1     13  6  4    23
##     2      7 25  5    37
##     3      4  3 33    40
##     Total 24 34 42   100
## 
##  Percent Correct:  0.71</code></pre>
<p>It produces a table of class <code>confusion.table</code> which inherits from calss <code>table</code>, and we also provide a print method.</p>
<p>The first argument to <code>confusion.glmnet</code> should be either a <code>glmnet</code> object, or a <code>cv.glmnet</code> object, from which predictions can be made, or a matrix/array of predictions, such as the <em>kept</em> <code>fit.predval</code> object from <code>cv.glmnet</code>.</p>
<p>In the second case we need to specify the <code>family</code>, otherwise <em>confusion</em> can exist between <code>binomial</code> and <code>multinomial</code> prediction matrices. Here we show a multinomial example</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1">cfit=<span class="kw"><a href="../reference/cv.glmnet.html">cv.glmnet</a></span>(x,y,<span class="dt">family=</span><span class="st">"multinomial"</span>,<span class="dt">type=</span><span class="st">"class"</span>,<span class="dt">keep=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2">cnf=<span class="kw"><a href="../reference/assess.glmnet.html">confusion.glmnet</a></span>(cfit<span class="op">$</span>fit.preval,<span class="dt">newy=</span>y,<span class="dt">family=</span><span class="st">"multinomial"</span>)</a>
<a class="sourceLine" id="cb36-3" data-line-number="3">which=<span class="kw"><a href="https://rdrr.io/r/base/match.html">match</a></span>(cfit<span class="op">$</span>lambda.min,cfit<span class="op">$</span>lambda)</a>
<a class="sourceLine" id="cb36-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(cnf[[which]])</a></code></pre></div>
<pre><code>##          True
## Predicted   1   2   3 Total
##     1      76  22  14   112
##     2      39 129  23   191
##     3      27  23 147   197
##     Total 142 174 184   500
## 
##  Percent Correct:  0.704</code></pre>
<p>Since the <code>fit.preval</code> object has predictions for the whole path, the result of <code>confusion.glmnet</code> here is a list of confusion tables. We identify and print the one corresponding to the minimum classification error.</p>
</div>
</div>
<div id="fitting-big-andor-sparse-glms" class="section level2">
<h2 class="hasAnchor">
<a href="#fitting-big-andor-sparse-glms" class="anchor"></a>Fitting big and/or sparse GLMs</h2>
<p>We include a function <code>bigGlm</code> for fitting a single GLM model (unpenalized), but allowing all the options of <code>glmnet</code>. In other words, coefficient upper and/or lower bounds and sparse <code>x</code> matrices. This is not too much more than fitting a model with a single value of <code>lambda=0</code> (with some protection from edge cases). There is also a <code>predict</code> and <code>print</code> method.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(BinomialExample)</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">fit=<span class="kw"><a href="../reference/bigGlm.html">bigGlm</a></span>(x,y,<span class="dt">family=</span><span class="st">"binomial"</span>,<span class="dt">lower.limits=</span><span class="op">-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb38-3" data-line-number="3"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(fit)</a></code></pre></div>
<pre><code>## 
## Call:  bigGlm(x = x, y = y, family = "binomial", lower.limits = -1) 
## 
##   Df   %Dev Lambda
## 1 30 0.7757      0</code></pre>
</div>
<div id="producing-x-from-mixed-variables-and-missing-data" class="section level2">
<h2 class="hasAnchor">
<a href="#producing-x-from-mixed-variables-and-missing-data" class="anchor"></a>Producing x from mixed variables, and missing data</h2>
<p>We have created a function <code>makeX</code> that makes it easy to create the model matrix <code>x</code> needed as input to <code>glmnet</code>. It takes as input a data frame, which can contain vectors, matrices and factors. Some of the features are</p>
<ul>
<li>Factors are <em>one-hot</em> encoded to form indicator matrices</li>
<li>Missing values in the resultant matrix can be replaced by the column means</li>
<li>The <code>sparse</code> option returns a matrix in column-sparse format. This is useful if the data are large, and factors have many levels.</li>
<li>
<p>Two dataframes can be provided, <code>train</code> and <code>test</code>. This ensures the factor levels correspond, and also imputes missing data in the test data from means in the training data.</p>
<p>We start with a simple case with some factors.</p>
</li>
</ul>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">101</span>)</a>
<a class="sourceLine" id="cb40-2" data-line-number="2">X =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="dv">20</span>),<span class="dv">10</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb40-3" data-line-number="3">X3=<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>],<span class="dv">10</span>,<span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb40-4" data-line-number="4">X4=<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(LETTERS[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>],<span class="dv">10</span>,<span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb40-5" data-line-number="5">df=<span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(X,X3,X4)</a>
<a class="sourceLine" id="cb40-6" data-line-number="6"><span class="kw"><a href="../reference/makeX.html">makeX</a></span>(df)</a></code></pre></div>
<pre><code>##            X1         X2 X3a X3b X3c X4A X4B X4C
## 1  -0.3260365  0.5264481   0   1   0   0   0   1
## 2   0.5524619 -0.7948444   0   0   1   0   1   0
## 3  -0.6749438  1.4277555   1   0   0   0   1   0
## 4   0.2143595 -1.4668197   1   0   0   1   0   0
## 5   0.3107692 -0.2366834   1   0   0   0   1   0
## 6   1.1739663 -0.1933380   0   1   0   1   0   0
## 7   0.6187899 -0.8497547   1   0   0   1   0   0
## 8  -0.1127343  0.0584655   0   1   0   1   0   0
## 9   0.9170283 -0.8176704   0   1   0   0   0   1
## 10 -0.2232594 -2.0503078   0   0   1   0   0   1</code></pre>
<p>Or if a sparse output was desired:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="kw"><a href="../reference/makeX.html">makeX</a></span>(df,<span class="dt">sparse=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 10 x 8 sparse Matrix of class "dgCMatrix"
##            X1         X2 X3a X3b X3c X4A X4B X4C
## 1  -0.3260365  0.5264481   .   1   .   .   .   1
## 2   0.5524619 -0.7948444   .   .   1   .   1   .
## 3  -0.6749438  1.4277555   1   .   .   .   1   .
## 4   0.2143595 -1.4668197   1   .   .   1   .   .
## 5   0.3107692 -0.2366834   1   .   .   .   1   .
## 6   1.1739663 -0.1933380   .   1   .   1   .   .
## 7   0.6187899 -0.8497547   1   .   .   1   .   .
## 8  -0.1127343  0.0584655   .   1   .   1   .   .
## 9   0.9170283 -0.8176704   .   1   .   .   .   1
## 10 -0.2232594 -2.0503078   .   .   1   .   .   1</code></pre>
<p>And now some missing values</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1">Xn=X</a>
<a class="sourceLine" id="cb44-2" data-line-number="2">Xn[<span class="dv">3</span>,<span class="dv">1</span>]=<span class="ot">NA</span>;Xn[<span class="dv">5</span>,<span class="dv">2</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb44-3" data-line-number="3">X3n=X3;</a>
<a class="sourceLine" id="cb44-4" data-line-number="4">X3n[<span class="dv">6</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb44-5" data-line-number="5">X4n=X4</a>
<a class="sourceLine" id="cb44-6" data-line-number="6">X4n[<span class="dv">9</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb44-7" data-line-number="7">dfn=<span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(Xn,X3n,X4n)</a>
<a class="sourceLine" id="cb44-8" data-line-number="8"><span class="kw"><a href="../reference/makeX.html">makeX</a></span>(dfn)</a></code></pre></div>
<pre><code>##            X1         X2 X3na X3nb X3nc X4nA X4nB X4nC
## 1  -0.3260365  0.5264481    0    1    0    0    0    1
## 2   0.5524619 -0.7948444    0    0    1    0    1    0
## 3          NA  1.4277555    1    0    0    0    1    0
## 4   0.2143595 -1.4668197    1    0    0    1    0    0
## 5   0.3107692         NA    1    0    0    0    1    0
## 6   1.1739663 -0.1933380   NA   NA   NA    1    0    0
## 7   0.6187899 -0.8497547    1    0    0    1    0    0
## 8  -0.1127343  0.0584655    0    1    0    1    0    0
## 9   0.9170283 -0.8176704    0    1    0   NA   NA   NA
## 10 -0.2232594 -2.0503078    0    0    1    0    0    1</code></pre>
<p>which we can replace with column-mean imputations (and make sparse, if we like)</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw"><a href="../reference/makeX.html">makeX</a></span>(dfn,<span class="dt">na.impute=</span><span class="ot">TRUE</span>,<span class="dt">sparse=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## 10 x 8 sparse Matrix of class "dgCMatrix"
##            X1         X2      X3na      X3nb      X3nc      X4nA      X4nB
## 1  -0.3260365  0.5264481 .         1.0000000 .         .         .        
## 2   0.5524619 -0.7948444 .         .         1.0000000 .         1.0000000
## 3   0.3472605  1.4277555 1.0000000 .         .         .         1.0000000
## 4   0.2143595 -1.4668197 1.0000000 .         .         1.0000000 .        
## 5   0.3107692 -0.4622295 1.0000000 .         .         .         1.0000000
## 6   1.1739663 -0.1933380 0.4444444 0.3333333 0.2222222 1.0000000 .        
## 7   0.6187899 -0.8497547 1.0000000 .         .         1.0000000 .        
## 8  -0.1127343  0.0584655 .         1.0000000 .         1.0000000 .        
## 9   0.9170283 -0.8176704 .         1.0000000 .         0.4444444 0.3333333
## 10 -0.2232594 -2.0503078 .         .         1.0000000 .         .        
##         X4nC
## 1  1.0000000
## 2  .        
## 3  .        
## 4  .        
## 5  .        
## 6  .        
## 7  .        
## 8  .        
## 9  0.2222222
## 10 1.0000000</code></pre>
<p>Finally if a test set is available as well</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">X =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="dv">10</span>),<span class="dv">5</span>,<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb48-2" data-line-number="2">X3=<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>],<span class="dv">5</span>,<span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-3" data-line-number="3">X4=<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(LETTERS[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>],<span class="dv">5</span>,<span class="dt">replace=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb48-4" data-line-number="4">Xn=X</a>
<a class="sourceLine" id="cb48-5" data-line-number="5">Xn[<span class="dv">3</span>,<span class="dv">1</span>]=<span class="ot">NA</span>;Xn[<span class="dv">5</span>,<span class="dv">2</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb48-6" data-line-number="6">X3n=X3;</a>
<a class="sourceLine" id="cb48-7" data-line-number="7">X3n[<span class="dv">1</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb48-8" data-line-number="8">X4n=X4</a>
<a class="sourceLine" id="cb48-9" data-line-number="9">X4n[<span class="dv">2</span>]=<span class="ot">NA</span></a>
<a class="sourceLine" id="cb48-10" data-line-number="10">dftn=<span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(Xn,X3n,X4n)</a>
<a class="sourceLine" id="cb48-11" data-line-number="11"><span class="kw"><a href="../reference/makeX.html">makeX</a></span>(dfn,dftn,<span class="dt">na.impute=</span><span class="ot">TRUE</span>, <span class="dt">sparse=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## $x
## 10 x 8 sparse Matrix of class "dgCMatrix"
##            X1         X2      X3na      X3nb      X3nc      X4nA      X4nB
## 1  -0.3260365  0.5264481 .         1.0000000 .         .         .        
## 2   0.5524619 -0.7948444 .         .         1.0000000 .         1.0000000
## 3   0.3472605  1.4277555 1.0000000 .         .         .         1.0000000
## 4   0.2143595 -1.4668197 1.0000000 .         .         1.0000000 .        
## 5   0.3107692 -0.4622295 1.0000000 .         .         .         1.0000000
## 6   1.1739663 -0.1933380 0.4444444 0.3333333 0.2222222 1.0000000 .        
## 7   0.6187899 -0.8497547 1.0000000 .         .         1.0000000 .        
## 8  -0.1127343  0.0584655 .         1.0000000 .         1.0000000 .        
## 9   0.9170283 -0.8176704 .         1.0000000 .         0.4444444 0.3333333
## 10 -0.2232594 -2.0503078 .         .         1.0000000 .         .        
##         X4nC
## 1  1.0000000
## 2  .        
## 3  .        
## 4  .        
## 5  .        
## 6  .        
## 7  .        
## 8  .        
## 9  0.2222222
## 10 1.0000000
## 
## $xtest
## 5 x 8 sparse Matrix of class "dgCMatrix"
##            X1         X2      X3na      X3nb      X3nc      X4nA      X4nB
## 11 -0.5098443 -0.7556130 0.4444444 0.3333333 0.2222222 .         1.0000000
## 12  1.5661805  1.7384118 .         .         1.0000000 0.4444444 0.3333333
## 13  0.3472605  0.7580952 .         1.0000000 .         .         1.0000000
## 14  1.0059925  2.1152294 1.0000000 .         .         1.0000000 .        
## 15 -0.5829222 -0.4622295 .         1.0000000 .         .         1.0000000
##         X4nC
## 11 .        
## 12 0.2222222
## 13 .        
## 14 .        
## 15 .</code></pre>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-glmnet">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” <em>Journal of Statistical Software, Articles</em> 33 (1): 1–22. <a href="https://doi.org/10.18637/jss.v033.i01" class="uri">https://doi.org/10.18637/jss.v033.i01</a>.</p>
</div>
<div id="ref-best_subset">
<p>Hastie, Trevor, Robert Tibshirani, and Ryan Tibshirani. 2017. “Extended Comparisons of Best Subset Selection, Forward Stepwise Selection, and the Lasso.”</p>
</div>
<div id="ref-block">
<p>Simon, Noah, Jerome Friedman, and Trevor Hastie. 2013. “A Blockwise Descent Algorithm for Group-Penalized Multiresponse and Multinomial Regression.”</p>
</div>
<div id="ref-coxnet">
<p>Simon, Noah, Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2011. “Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent.” <em>Journal of Statistical Software, Articles</em> 39 (5): 1–13. <a href="https://doi.org/10.18637/jss.v039.i05" class="uri">https://doi.org/10.18637/jss.v039.i05</a>.</p>
</div>
<div id="ref-strongrules">
<p>Tibshirani, Robert, Jacob Bien, Jerome Friedman, Trevor Hastie, Noah Simon, Jonathan Taylor, and Ryan Tibshirani. 2012. “Strong Rules for Discarding Predictors in Lasso-Type Problems.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 74 (2): 245–66. <a href="https://doi.org/10.1111/j.1467-9868.2011.01004.x" class="uri">https://doi.org/10.1111/j.1467-9868.2011.01004.x</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#simple-relaxed-fit">Simple relaxed fit</a></li>
      <li><a href="#more-details-on-relaxed-fitting">More details on relaxed fitting</a></li>
      <li><a href="#relaxed-fits-and-glms">Relaxed fits and glms</a></li>
      <li><a href="#progress-bar">Progress bar</a></li>
      <li><a href="#c-index-for-cox-models">C index for Cox models</a></li>
      <li><a href="#assessing-models-on-test-data">Assessing models on test data</a></li>
      <li><a href="#fitting-big-andor-sparse-glms">Fitting big and/or sparse GLMs</a></li>
      <li><a href="#producing-x-from-mixed-variables-and-missing-data">Producing x from mixed variables, and missing data</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Jerome Friedman, Trevor Hastie, Rob Tibshirani, Balasubramanian Narasimhan, Noah Simon.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
